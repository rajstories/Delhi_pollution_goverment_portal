/**
 * ============================================================================
 * DELHI POLLUTION COMMAND CENTER - DISTRIBUTED JOB PROCESSOR
 * ============================================================================
 * 
 * Module: worker.js
 * Layer: Scalability & Async Processing
 * Pattern: Event-Driven Architecture with Message Queue
 * 
 * Architecture Overview:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚                    HORIZONTAL SCALING ARCHITECTURE                       â”‚
 * â”‚                                                                          â”‚
 * â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
 * â”‚   â”‚Worker 1 â”‚  â”‚Worker 2 â”‚  â”‚Worker 3 â”‚  â”‚Worker N â”‚  â”‚Worker N+1â”‚     â”‚
 * â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â”‚
 * â”‚        â”‚            â”‚            â”‚            â”‚            â”‚           â”‚
 * â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
 * â”‚                                  â”‚                                      â”‚
 * â”‚                                  â–¼                                      â”‚
 * â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
 * â”‚                    â”‚      Redis Cluster      â”‚                          â”‚
 * â”‚                    â”‚    (BullMQ Backend)     â”‚                          â”‚
 * â”‚                    â”‚                         â”‚                          â”‚
 * â”‚                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                          â”‚
 * â”‚                    â”‚  â”‚ pollution-      â”‚    â”‚                          â”‚
 * â”‚                    â”‚  â”‚ reports-v1      â”‚    â”‚                          â”‚
 * â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                          â”‚
 * â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
 * â”‚                                                                          â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 * 
 * Stateless Horizontal Scaling:
 * - Each worker instance is identical and stateless
 * - Workers compete for jobs using Redis atomic operations
 * - No shared state between workers (all state in Redis/DB)
 * - Can scale from 1 to 1000+ workers without code changes
 * - Kubernetes HPA scales based on queue depth metrics
 * 
 * @author Platform Engineering Team
 * @version 3.1.0
 * @since 2024-02-01
 */

'use strict';

// ============================================================================
// DEPENDENCY IMPORTS - Mock implementations for demonstration
// ============================================================================

/**
 * Mock BullMQ Implementation
 * 
 * In production: npm install bullmq ioredis
 * 
 * BullMQ Features Used:
 * - Distributed job locking (prevents duplicate processing)
 * - Automatic retries with exponential backoff
 * - Job prioritization and delayed jobs
 * - Rate limiting per queue
 * - Job progress tracking
 * - Stalled job recovery
 */
const Queue = {
    name: 'pollution-reports-v1',
    
    /**
     * Add job to queue
     * @param {string} name - Job type identifier
     * @param {Object} data - Job payload
     * @param {Object} opts - Job options (priority, delay, attempts)
     */
    add: async (name, data, opts = {}) => {
        console.log(`[QUEUE] Job added: ${name}`, { data, opts });
        return { id: `job_${Date.now()}`, name, data };
    }
};

/**
 * Worker class mock for demonstration
 */
class Worker {
    constructor(queueName, processor, options = {}) {
        this.queueName = queueName;
        this.processor = processor;
        this.options = options;
        this.isRunning = false;
    }

    async run() {
        this.isRunning = true;
        console.log(`[WORKER] Started processing queue: ${this.queueName}`);
    }

    on(event, handler) {
        console.log(`[WORKER] Event handler registered: ${event}`);
    }

    async close() {
        this.isRunning = false;
        console.log('[WORKER] Gracefully shutting down...');
    }
}

// ============================================================================
// CONFIGURATION
// ============================================================================

/**
 * Worker Configuration
 * 
 * Non-blocking Event Loop Optimization:
 * - Each job runs in isolated async context
 * - CPU-intensive tasks offloaded to worker threads
 * - I/O operations are non-blocking by default
 * - Event loop never blocked for >100ms (monitored)
 */
const WORKER_CONFIG = {
    // Redis connection for BullMQ
    REDIS: {
        HOST: process.env.REDIS_HOST || 'redis-cluster.internal',
        PORT: parseInt(process.env.REDIS_PORT, 10) || 6379,
        PASSWORD: process.env.REDIS_PASSWORD,
        // Use TLS in production
        TLS: process.env.NODE_ENV === 'production'
    },

    // Queue-specific settings
    QUEUE: {
        NAME: 'pollution-reports-v1',
        // Concurrency per worker instance
        CONCURRENCY: parseInt(process.env.WORKER_CONCURRENCY, 10) || 10,
        // Lock duration for job processing
        LOCK_DURATION: 30000,
        // Stalled job check interval
        STALLED_INTERVAL: 5000
    },

    // Retry configuration with exponential backoff
    RETRY: {
        MAX_ATTEMPTS: 5,
        BACKOFF: {
            TYPE: 'exponential',
            DELAY: 1000  // Base delay in ms
        }
    },

    // Job timeout settings
    TIMEOUT: {
        JOB_DEFAULT: 60000,        // 1 minute default
        GEO_VERIFICATION: 10000,   // 10 seconds
        AI_ANALYSIS: 45000,        // 45 seconds
        DATA_ENRICHMENT: 15000     // 15 seconds
    }
};

// ============================================================================
// GEO-FENCING SERVICE
// ============================================================================

/**
 * Geographic Verification Service
 * 
 * Validates that pollution reports originate from within
 * the Delhi NCR administrative boundary.
 * 
 * Boundary Definition:
 * - Delhi NCR polygon coordinates (GeoJSON)
 * - 50m tolerance buffer for GPS inaccuracy
 * - Includes satellite cities: Noida, Gurgaon, Faridabad, Ghaziabad
 * 
 * @param {Object} reportData - Pollution report with coordinates
 * @returns {Promise<Object>} Verification result
 */
async function verifyGeoFencing(reportData) {
    const startTime = Date.now();

    /**
     * Stateless Horizontal Scaling Note:
     * 
     * This function is completely stateless - all required data
     * is passed in via reportData. The GeoJSON boundary is loaded
     * from a shared configuration service (not local state).
     * 
     * This allows any worker instance to process any job without
     * requiring sticky sessions or local caches.
     */

    // Simulate GeoJSON point-in-polygon check
    await simulateAsyncOperation(50, 150);

    const { latitude, longitude } = reportData.location || {};

    // Delhi NCR approximate bounding box
    const DELHI_NCR_BOUNDS = {
        minLat: 28.4000,
        maxLat: 28.8500,
        minLng: 76.8500,
        maxLng: 77.5500
    };

    const isWithinBounds = latitude && longitude &&
        latitude >= DELHI_NCR_BOUNDS.minLat &&
        latitude <= DELHI_NCR_BOUNDS.maxLat &&
        longitude >= DELHI_NCR_BOUNDS.minLng &&
        longitude <= DELHI_NCR_BOUNDS.maxLng;

    const result = {
        verified: isWithinBounds,
        confidence: isWithinBounds ? 98.5 : 0,
        boundaryCheck: {
            method: 'GEOJSON_POLYGON',
            tolerance: '50m',
            projection: 'EPSG:4326'
        },
        administrativeZone: isWithinBounds ? 'DELHI_NCR' : 'OUT_OF_BOUNDS',
        processingTimeMs: Date.now() - startTime
    };

    return result;
}

// ============================================================================
// AI ANALYSIS SERVICE
// ============================================================================

/**
 * AI-Powered Pollution Report Analysis
 * 
 * Multi-model ensemble for comprehensive analysis:
 * 
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚                      AI ANALYSIS PIPELINE                                â”‚
 * â”‚                                                                          â”‚
 * â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
 * â”‚  â”‚   Image     â”‚    â”‚   Text      â”‚    â”‚  Sensor     â”‚                 â”‚
 * â”‚  â”‚ Classificationâ”‚  â”‚   NLP       â”‚    â”‚  Validation â”‚                 â”‚
 * â”‚  â”‚  (ResNet50) â”‚    â”‚  (BERT)     â”‚    â”‚  (XGBoost)  â”‚                 â”‚
 * â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚
 * â”‚         â”‚                  â”‚                  â”‚                         â”‚
 * â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
 * â”‚                            â–¼                                            â”‚
 * â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
 * â”‚                   â”‚    Ensemble     â”‚                                   â”‚
 * â”‚                   â”‚   Aggregator    â”‚                                   â”‚
 * â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
 * â”‚                            â”‚                                            â”‚
 * â”‚                            â–¼                                            â”‚
 * â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
 * â”‚                   â”‚  Confidence     â”‚                                   â”‚
 * â”‚                   â”‚    Score        â”‚                                   â”‚
 * â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 * 
 * @param {Object} reportData - Pollution report data
 * @returns {Promise<Object>} AI analysis results
 */
async function runAIAnalysis(reportData) {
    const startTime = Date.now();

    /**
     * Non-blocking Event Loop Implementation:
     * 
     * All AI model inference calls are non-blocking:
     * 1. HTTP calls to ML serving endpoints (async I/O)
     * 2. Results aggregated using Promise.all()
     * 3. Event loop remains free during network wait
     * 
     * For CPU-bound preprocessing (if any), we use:
     * - Worker threads for image resizing
     * - Stream processing for large payloads
     */

    // Parallel model inference (non-blocking)
    const [imageAnalysis, textAnalysis, sensorValidation] = await Promise.all([
        analyzeImage(reportData.imageUrl),
        analyzeText(reportData.description),
        validateSensorData(reportData.sensorReadings)
    ]);

    // Ensemble aggregation
    const confidenceScores = [
        imageAnalysis.confidence * 0.4,   // 40% weight
        textAnalysis.confidence * 0.3,    // 30% weight
        sensorValidation.confidence * 0.3 // 30% weight
    ];

    const aggregatedConfidence = confidenceScores.reduce((a, b) => a + b, 0);

    const result = {
        overallConfidence: parseFloat(aggregatedConfidence.toFixed(1)),
        breakdown: {
            imageClassification: {
                model: 'ResNet50-PollutionV3',
                confidence: imageAnalysis.confidence,
                detectedCategories: imageAnalysis.categories
            },
            textAnalysis: {
                model: 'BERT-PollutionNER',
                confidence: textAnalysis.confidence,
                extractedEntities: textAnalysis.entities
            },
            sensorValidation: {
                model: 'XGBoost-SensorAnomaly',
                confidence: sensorValidation.confidence,
                anomaliesDetected: sensorValidation.anomalies
            }
        },
        recommendation: aggregatedConfidence > 80 ? 'AUTO_APPROVE' : 'MANUAL_REVIEW',
        processingTimeMs: Date.now() - startTime
    };

    return result;
}

/**
 * Image analysis mock
 */
async function analyzeImage(imageUrl) {
    await simulateAsyncOperation(100, 300);
    return {
        confidence: 97.2,
        categories: ['industrial_emission', 'vehicle_exhaust', 'dust_pollution']
    };
}

/**
 * Text analysis mock
 */
async function analyzeText(description) {
    await simulateAsyncOperation(50, 150);
    return {
        confidence: 96.8,
        entities: ['factory', 'smoke', 'respiratory_issues', 'morning_hours']
    };
}

/**
 * Sensor data validation mock
 */
async function validateSensorData(readings) {
    await simulateAsyncOperation(30, 100);
    return {
        confidence: 99.1,
        anomalies: [],
        calibrationStatus: 'VALID'
    };
}

// ============================================================================
// DATA ENRICHMENT SERVICE
// ============================================================================

/**
 * Enrich pollution report with contextual data
 * 
 * Data sources:
 * - Weather API (temperature, humidity, wind)
 * - Traffic density from Google Maps API
 * - Historical pollution data from TimescaleDB
 * - Nearby industrial activity from registry
 * 
 * @param {Object} reportData - Original report
 * @returns {Promise<Object>} Enriched report
 */
async function enrichReportData(reportData) {
    await simulateAsyncOperation(50, 200);

    return {
        weather: {
            temperature: 28.5,
            humidity: 65,
            windSpeed: 12.3,
            windDirection: 'NW',
            source: 'IMD_API_v2'
        },
        traffic: {
            density: 'HIGH',
            nearbyVehicles: 2500,
            source: 'TRAFFIC_MANAGEMENT_SYSTEM'
        },
        historical: {
            avgPM25_7d: 156.3,
            avgPM10_7d: 234.7,
            trend: 'INCREASING'
        },
        nearbyIndustries: [
            { name: 'Industrial Zone A', distance: '2.3km', type: 'MANUFACTURING' },
            { name: 'Thermal Plant B', distance: '5.1km', type: 'POWER_GENERATION' }
        ]
    };
}

// ============================================================================
// UTILITY FUNCTIONS
// ============================================================================

/**
 * Simulate async operation with realistic timing
 * 
 * @param {number} minMs - Minimum delay
 * @param {number} maxMs - Maximum delay
 */
async function simulateAsyncOperation(minMs, maxMs) {
    const delay = Math.floor(Math.random() * (maxMs - minMs + 1)) + minMs;
    return new Promise(resolve => setTimeout(resolve, delay));
}

/**
 * Structured logging for observability
 * 
 * Log format compatible with:
 * - ELK Stack (Elasticsearch, Logstash, Kibana)
 * - Datadog APM
 * - AWS CloudWatch Logs Insights
 */
function workerLog(level, message, metadata = {}) {
    const logEntry = {
        timestamp: new Date().toISOString(),
        level,
        service: 'dpcc-worker',
        queue: WORKER_CONFIG.QUEUE.NAME,
        workerId: process.env.HOSTNAME || `worker-${process.pid}`,
        message,
        ...metadata
    };

    console.log(JSON.stringify(logEntry));
}

// ============================================================================
// MAIN JOB PROCESSOR
// ============================================================================

/**
 * Primary job processing function
 * 
 * Job Lifecycle:
 * 1. Job claimed from Redis (atomic BRPOPLPUSH)
 * 2. Lock acquired (prevents duplicate processing)
 * 3. Processing stages executed sequentially
 * 4. Progress updated at each stage
 * 5. Result stored in Redis
 * 6. Job marked complete (removed from active list)
 * 
 * @param {Object} job - BullMQ job object
 * @returns {Promise<Object>} Processing result
 */
async function processJob(job) {
    const jobStartTime = Date.now();

    workerLog('INFO', `âš¡ Job Received: ID ${job.id}`, {
        jobId: job.id,
        jobName: job.name,
        attempt: job.attemptsMade + 1,
        maxAttempts: WORKER_CONFIG.RETRY.MAX_ATTEMPTS
    });

    try {
        // ====================================================================
        // STAGE 1: Input Validation (5% progress)
        // ====================================================================
        
        await job.updateProgress(5);
        
        if (!job.data || !job.data.reportId) {
            throw new Error('Invalid job data: missing reportId');
        }

        const reportData = {
            reportId: job.data.reportId,
            location: job.data.location || { latitude: 28.6139, longitude: 77.2090 },
            description: job.data.description || '',
            imageUrl: job.data.imageUrl,
            sensorReadings: job.data.sensorReadings || {},
            submittedAt: job.data.submittedAt || new Date().toISOString()
        };

        // ====================================================================
        // STAGE 2: Geo-Fencing Verification (25% progress)
        // ====================================================================
        
        await job.updateProgress(15);
        
        const geoResult = await verifyGeoFencing(reportData);
        
        if (geoResult.verified) {
            workerLog('INFO', 'âœ… Geo-Verification Passed', {
                jobId: job.id,
                zone: geoResult.administrativeZone,
                confidence: geoResult.confidence
            });
        } else {
            workerLog('WARN', 'âš ï¸ Geo-Verification Failed - Out of bounds', {
                jobId: job.id,
                location: reportData.location
            });
            // Don't fail - flag for manual review
        }

        await job.updateProgress(25);

        // ====================================================================
        // STAGE 3: AI Analysis (65% progress)
        // ====================================================================
        
        await job.updateProgress(35);

        const aiResult = await runAIAnalysis(reportData);

        workerLog('INFO', `ðŸ§  AI Confidence Score: ${aiResult.overallConfidence}%`, {
            jobId: job.id,
            confidence: aiResult.overallConfidence,
            recommendation: aiResult.recommendation,
            modelBreakdown: {
                image: aiResult.breakdown.imageClassification.confidence,
                text: aiResult.breakdown.textAnalysis.confidence,
                sensor: aiResult.breakdown.sensorValidation.confidence
            }
        });

        await job.updateProgress(65);

        // ====================================================================
        // STAGE 4: Data Enrichment (85% progress)
        // ====================================================================
        
        const enrichedData = await enrichReportData(reportData);
        
        await job.updateProgress(85);

        // ====================================================================
        // STAGE 5: Result Compilation (100% progress)
        // ====================================================================
        
        const processingResult = {
            reportId: reportData.reportId,
            status: 'PROCESSED',
            processingTimeMs: Date.now() - jobStartTime,
            verification: {
                geo: geoResult,
                ai: aiResult
            },
            enrichment: enrichedData,
            finalDecision: {
                action: aiResult.recommendation,
                confidence: aiResult.overallConfidence,
                geoVerified: geoResult.verified,
                timestamp: new Date().toISOString()
            },
            metadata: {
                workerId: process.env.HOSTNAME || `worker-${process.pid}`,
                queueName: WORKER_CONFIG.QUEUE.NAME,
                attempt: job.attemptsMade + 1
            }
        };

        await job.updateProgress(100);

        workerLog('INFO', `âœ… Job Completed: ID ${job.id}`, {
            jobId: job.id,
            processingTimeMs: processingResult.processingTimeMs,
            decision: processingResult.finalDecision.action
        });

        return processingResult;

    } catch (error) {
        workerLog('ERROR', `âŒ Job Failed: ID ${job.id}`, {
            jobId: job.id,
            error: error.message,
            stack: error.stack,
            attempt: job.attemptsMade + 1
        });

        // Rethrow to trigger BullMQ retry mechanism
        throw error;
    }
}

// ============================================================================
// WORKER INITIALIZATION
// ============================================================================

/**
 * Initialize and start the worker
 * 
 * Graceful Shutdown Handling:
 * - SIGTERM: Complete current job, then exit
 * - SIGINT: Same as SIGTERM
 * - Kubernetes preStop hook sends SIGTERM
 * - 30-second grace period before SIGKILL
 */
async function initializeWorker() {
    workerLog('INFO', 'ðŸš€ Initializing worker instance', {
        queue: WORKER_CONFIG.QUEUE.NAME,
        concurrency: WORKER_CONFIG.QUEUE.CONCURRENCY,
        nodeEnv: process.env.NODE_ENV || 'development'
    });

    // Create worker instance
    const worker = new Worker(
        WORKER_CONFIG.QUEUE.NAME,
        processJob,
        {
            concurrency: WORKER_CONFIG.QUEUE.CONCURRENCY,
            lockDuration: WORKER_CONFIG.QUEUE.LOCK_DURATION,
            stalledInterval: WORKER_CONFIG.QUEUE.STALLED_INTERVAL,
            // Redis connection
            connection: {
                host: WORKER_CONFIG.REDIS.HOST,
                port: WORKER_CONFIG.REDIS.PORT,
                password: WORKER_CONFIG.REDIS.PASSWORD
            }
        }
    );

    // Event handlers for observability
    worker.on('completed', (job, result) => {
        workerLog('DEBUG', `Job ${job.id} completed successfully`);
    });

    worker.on('failed', (job, error) => {
        workerLog('ERROR', `Job ${job?.id} failed`, {
            error: error.message,
            willRetry: (job?.attemptsMade || 0) < WORKER_CONFIG.RETRY.MAX_ATTEMPTS
        });
    });

    worker.on('stalled', (jobId) => {
        workerLog('WARN', `Job ${jobId} stalled - will be reprocessed`);
    });

    // Graceful shutdown
    const shutdown = async (signal) => {
        workerLog('INFO', `Received ${signal}, initiating graceful shutdown...`);
        await worker.close();
        workerLog('INFO', 'Worker shutdown complete');
        process.exit(0);
    };

    process.on('SIGTERM', () => shutdown('SIGTERM'));
    process.on('SIGINT', () => shutdown('SIGINT'));

    // Start processing
    await worker.run();

    workerLog('INFO', 'âœ… Worker is now processing jobs', {
        queue: WORKER_CONFIG.QUEUE.NAME
    });

    return worker;
}

// ============================================================================
// MODULE EXPORTS
// ============================================================================

module.exports = {
    initializeWorker,
    processJob,
    verifyGeoFencing,
    runAIAnalysis,
    enrichReportData,
    WORKER_CONFIG,
    // For testing
    _internal: {
        analyzeImage,
        analyzeText,
        validateSensorData,
        workerLog
    }
};

// ============================================================================
// MAIN ENTRY POINT
// ============================================================================

// Auto-start if run directly (not imported)
if (require.main === module) {
    initializeWorker().catch((error) => {
        console.error('Failed to initialize worker:', error);
        process.exit(1);
    });
}
